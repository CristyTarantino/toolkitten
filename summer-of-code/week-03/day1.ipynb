{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Million Women To Tech:  Summer of Code\n",
    "\n",
    "## Week 3 - Intro to NLP \n",
    "\n",
    "### Day 1\n",
    "\n",
    "### Chapter 0. - Preface \n",
    "\n",
    "http://www.nltk.org/book/ch00.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'file.txt'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-702c05a3379f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"file.txt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ing'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'file.txt'"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "for line in open(\"file.txt\"):\n",
    "    for word in line.split():\n",
    "        if word.endswith('ing'):\n",
    "            print(word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chapter 1. - Language Processing and Python\n",
    "\n",
    "http://www.nltk.org/book/ch01.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading collection 'book'\n[nltk_data]    | \n[nltk_data]    | Downloading package abc to ./nltk_data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data]    |   Unzipping corpora/abc.zip.\n[nltk_data]    | Downloading package brown to ./nltk_data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data]    |   Unzipping corpora/brown.zip.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data]    | Downloading package chat80 to ./nltk_data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data]    |   Unzipping corpora/chat80.zip.\n[nltk_data]    | Downloading package cmudict to ./nltk_data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data]    |   Unzipping corpora/cmudict.zip.\n[nltk_data]    | Downloading package conll2000 to ./nltk_data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data]    |   Unzipping corpora/conll2000.zip.\n[nltk_data]    | Downloading package conll2002 to ./nltk_data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data]    |   Unzipping corpora/conll2002.zip.\n[nltk_data]    | Downloading package dependency_treebank to\n[nltk_data]    |     ./nltk_data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data]    |   Unzipping corpora/dependency_treebank.zip.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data]    | Downloading package genesis to ./nltk_data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data]    |   Unzipping corpora/genesis.zip.\n[nltk_data]    | Downloading package gutenberg to ./nltk_data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data]    |   Unzipping corpora/gutenberg.zip.\n[nltk_data]    | Downloading package ieer to ./nltk_data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data]    |   Unzipping corpora/ieer.zip.\n[nltk_data]    | Downloading package inaugural to ./nltk_data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data]    |   Unzipping corpora/inaugural.zip.\n[nltk_data]    | Downloading package movie_reviews to ./nltk_data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data]    |   Unzipping corpora/movie_reviews.zip.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data]    | Downloading package nps_chat to ./nltk_data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data]    |   Unzipping corpora/nps_chat.zip.\n[nltk_data]    | Downloading package names to ./nltk_data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data]    |   Unzipping corpora/names.zip.\n[nltk_data]    | Downloading package ppattach to ./nltk_data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data]    |   Unzipping corpora/ppattach.zip.\n[nltk_data]    | Downloading package reuters to ./nltk_data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data]    | Downloading package senseval to ./nltk_data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data]    |   Unzipping corpora/senseval.zip.\n[nltk_data]    | Downloading package state_union to ./nltk_data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data]    |   Unzipping corpora/state_union.zip.\n[nltk_data]    | Downloading package stopwords to ./nltk_data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data]    |   Unzipping corpora/stopwords.zip.\n[nltk_data]    | Downloading package swadesh to ./nltk_data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data]    |   Unzipping corpora/swadesh.zip.\n[nltk_data]    | Downloading package timit to ./nltk_data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data]    |   Unzipping corpora/timit.zip.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data]    | Downloading package treebank to ./nltk_data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data]    |   Unzipping corpora/treebank.zip.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data]    | Downloading package toolbox to ./nltk_data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data]    |   Unzipping corpora/toolbox.zip.\n[nltk_data]    | Downloading package udhr to ./nltk_data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data]    |   Unzipping corpora/udhr.zip.\n[nltk_data]    | Downloading package udhr2 to ./nltk_data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data]    |   Unzipping corpora/udhr2.zip.\n[nltk_data]    | Downloading package unicode_samples to ./nltk_data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data]    |   Unzipping corpora/unicode_samples.zip.\n[nltk_data]    | Downloading package webtext to ./nltk_data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data]    |   Unzipping corpora/webtext.zip.\n[nltk_data]    | Downloading package wordnet to ./nltk_data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data]    |   Unzipping corpora/wordnet.zip.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data]    | Downloading package wordnet_ic to ./nltk_data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data]    |   Unzipping corpora/wordnet_ic.zip.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data]    | Downloading package words to ./nltk_data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data]    |   Unzipping corpora/words.zip.\n[nltk_data]    | Downloading package maxent_treebank_pos_tagger to\n[nltk_data]    |     ./nltk_data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data]    |   Unzipping taggers/maxent_treebank_pos_tagger.zip.\n[nltk_data]    | Downloading package maxent_ne_chunker to\n[nltk_data]    |     ./nltk_data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data]    |   Unzipping chunkers/maxent_ne_chunker.zip.\n[nltk_data]    | Downloading package universal_tagset to\n[nltk_data]    |     ./nltk_data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data]    |   Unzipping taggers/universal_tagset.zip.\n[nltk_data]    | Downloading package punkt to ./nltk_data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data]    |   Unzipping tokenizers/punkt.zip.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data]    | Downloading package book_grammars to ./nltk_data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data]    |   Unzipping grammars/book_grammars.zip.\n[nltk_data]    | Downloading package city_database to ./nltk_data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data]    |   Unzipping corpora/city_database.zip.\n[nltk_data]    | Downloading package tagsets to ./nltk_data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data]    |   Unzipping help/tagsets.zip.\n[nltk_data]    | Downloading package panlex_swadesh to ./nltk_data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n[nltk_data]    |     ./nltk_data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data]    |   Unzipping taggers/averaged_perceptron_tagger.zip.\n[nltk_data]    | \n[nltk_data]  Done downloading collection book\n*** Introductory Examples for the NLTK Book ***\nLoading text1, ..., text9 and sent1, ..., sent9\nType the name of the text or sentence to view it.\nType: 'texts()' or 'sents()' to list the materials.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text1: Moby Dick by Herman Melville 1851\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text2: Sense and Sensibility by Jane Austen 1811\ntext3: The Book of Genesis\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text4: Inaugural Address Corpus\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text5: Chat Corpus\ntext6: Monty Python and the Holy Grail\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text7: Wall Street Journal\ntext8: Personals Corpus\ntext9: The Man Who Was Thursday by G . K . Chesterton 1908\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download(\"book\", download_dir='./nltk_data')\n",
    "nltk.data.path.append('./nltk_data')\n",
    "from nltk.book import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sent1: Call me Ishmael .\n",
      "sent2: The family of Dashwood had long been settled in Sussex .\n",
      "sent3: In the beginning God created the heaven and the earth .\n",
      "sent4: Fellow - Citizens of the Senate and of the House of Representatives :\n",
      "sent5: I have a problem with people PMing me to lol JOIN\n",
      "sent6: SCENE 1 : [ wind ] [ clop clop clop ] KING ARTHUR : Whoa there !\n",
      "sent7: Pierre Vinken , 61 years old , will join the board as a nonexecutive director Nov. 29 .\n",
      "sent8: 25 SEXY MALE , seeks attrac older single lady , for discreet encounters .\n",
      "sent9: THE suburb of Saffron Park lay on the sunset side of London , as red and ragged as a cloud of sunset .\n"
     ]
    }
   ],
   "source": [
    "sents()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text1: Moby Dick by Herman Melville 1851\n",
      "text2: Sense and Sensibility by Jane Austen 1811\n",
      "text3: The Book of Genesis\n",
      "text4: Inaugural Address Corpus\n",
      "text5: Chat Corpus\n",
      "text6: Monty Python and the Holy Grail\n",
      "text7: Wall Street Journal\n",
      "text8: Personals Corpus\n",
      "text9: The Man Who Was Thursday by G . K . Chesterton 1908\n"
     ]
    }
   ],
   "source": [
    "texts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Displaying 11 of 11 matches:\n",
      "ong the former , one was of a most monstrous size . ... This came towards us , \n",
      "ON OF THE PSALMS . \" Touching that monstrous bulk of the whale or ork we have r\n",
      "ll over with a heathenish array of monstrous clubs and spears . Some were thick\n",
      "d as you gazed , and wondered what monstrous cannibal and savage could ever hav\n",
      "that has survived the flood ; most monstrous and most mountainous ! That Himmal\n",
      "they might scout at Moby Dick as a monstrous fable , or still worse and more de\n",
      "th of Radney .'\" CHAPTER 55 Of the Monstrous Pictures of Whales . I shall ere l\n",
      "ing Scenes . In connexion with the monstrous pictures of whales , I am strongly\n",
      "ere to enter upon those still more monstrous stories of them which are to be fo\n",
      "ght have been rummaged out of this monstrous cabinet there is no telling . But \n",
      "of Whale - Bones ; for Whales of a monstrous size are oftentimes cast up dead u\n"
     ]
    }
   ],
   "source": [
    "text1.concordance(\"monstrous\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Displaying 25 of 25 matches:\n",
      "els sing ] Arthur , this is the Holy Grail . Look well , Arthur , for it is you\n",
      " it is your sacred task to seek this grail . That is your purpose , Arthur ... \n",
      " , Arthur ... the quest for the Holy Grail . [ boom ] [ singing stops ] LAUNCEL\n",
      "an join us in our quest for the Holy Grail . FRENCH GUARD : Well , I ' ll ask h\n",
      "ARTHUR : If you will not show us the Grail , we shall take your castle by force\n",
      "s required if the quest for the Holy Grail were to be brought to a successful c\n",
      "should separate , and search for the Grail individually . [ clop clop clop ] No\n",
      "AD : You are the keepers of the Holy Grail ? ZOOT : The what ? GALAHAD : The Gr\n",
      "il ? ZOOT : The what ? GALAHAD : The Grail . It is here . ZOOT : Oh , but you a\n",
      "ease ! In God ' s name , show me the Grail ! ZOOT : Oh , you have suffered much\n",
      "rment me no longer . I have seen the Grail ! PIGLET : There ' s no grail here .\n",
      "en the Grail ! PIGLET : There ' s no grail here . GALAHAD : I have seen it ! I \n",
      "are you going ? GALAHAD : I seek the Grail ! I have seen it , here in this cast\n",
      " which , I have just remembered , is grail - shaped . It ' s not the first time\n",
      "blem . GALAHAD : It ' s not the real Grail ? DINGO : Oh , wicked , bad , naught\n",
      "ne punishment for setting alight the grail - shaped beacon . You must tie her d\n",
      " : No , we ' ve got to find the Holy Grail . Come on ! GALAHAD : Oh , let me ha\n",
      " , but they were still no nearer the Grail . Meanwhile , King Arthur and Sir Be\n",
      " of whom you speak , he has seen the Grail ? OLD MAN : ... Ha ha ha ha ! Heh , \n",
      "o man has entered . ARTHUR : And the Grail . The Grail is there ? OLD MAN : The\n",
      "tered . ARTHUR : And the Grail . The Grail is there ? OLD MAN : There is much d\n",
      " has ever crossed . ARTHUR : But the Grail ! Where is the Grail ?! OLD MAN : Se\n",
      "RTHUR : But the Grail ! Where is the Grail ?! OLD MAN : Seek you the Bridge of \n",
      "Bridge of Death , which leads to the Grail ? OLD MAN : Heh , hee hee hee hee ! \n",
      "e the sign that leads us to the Holy Grail ! Brave , brave Concorde , you shall\n"
     ]
    }
   ],
   "source": [
    "text6.concordance(\"Grail\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Displaying 21 of 21 matches:\n",
      "D God had taken from man , made he a woman , and brought her unto the man . And\n",
      " flesh of my fle she shall be called Woman , because she was taken out of Man .\n",
      " God had made . And he said unto the woman , Yea , hath God said , Ye shall not\n",
      "f every tree of the garden ? And the woman said unto the serpent , We may eat o\n",
      " die . And the serpent said unto the woman , Ye shall not surely die : For God \n",
      "knowing good and evil . And when the woman saw that the tree was good for food \n",
      "est not eat ? And the man said , The woman whom thou gavest to be with me , she\n",
      "eat . And the LORD God said unto the woman , What is this that thou hast done ?\n",
      "s this that thou hast done ? And the woman said , The serpent beguiled me , and\n",
      "will put enmity between thee and the woman , and between thy seed and her seed \n",
      "hou shalt bruise his heel . Unto the woman he said , I will greatly multiply th\n",
      "ld now , I know that thou art a fair woman to look up Therefore it shall come t\n",
      "nto Egypt , the Egyptians beheld the woman that she was very fair . The princes\n",
      "d commended her before Phara and the woman was taken into Pharaoh ' s house . A\n",
      " , thou art but a dead man , for the woman which thou hast taken ; for she is a\n",
      "ant said unto him , Peradventure the woman will not be willing to follow me unt\n",
      "unto my son from thence . And if the woman will not be willing to follow thee ,\n",
      "id unto my master , Peradventure the woman will not follow me . And he said unt\n",
      "raw for thy came let the same be the woman whom the LORD hath appointed out for\n",
      "ite , to receive his pledge from the woman ' s ha but he found her not . Then h\n",
      ", and Shaul the son of a Canaanitish woman . And the sons of Levi ; Gershon , K\n"
     ]
    }
   ],
   "source": [
    "# Is there a way for the output to display which line the \n",
    "# search term was found on? - Elle J\n",
    "\n",
    "text3.concordance(\"woman\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Displaying 25 of 25 matches:\n",
      "was good . And God said , Let us make man in our image , after our likene and l\n",
      "epeth upon the earth . So God created man in his own image , in the image of Go\n",
      " upon the earth , and there was not a man to till the ground . But there went u\n",
      " the ground . And the LORD God formed man of the dust of the ground , and breat\n",
      "his nostrils the breath of life ; and man became a living soul . And the LORD G\n",
      "stward in Eden ; and there he put the man whom he had formed . And out of the g\n",
      "Euphrates . And the LORD God took the man , and put him into the garden of Eden\n",
      "p it . And the LORD God commanded the man , saying , Of every tree of the garde\n",
      "RD God said , It is not good that the man should be alone ; I will make him an \n",
      "b , which the LORD God had taken from man , made he a woman , and brought her u\n",
      "he a woman , and brought her unto the man . And Adam said , This is now bone of\n",
      " Woman , because she was taken out of Man . Therefore shall a man leave his fat\n",
      " taken out of Man . Therefore shall a man leave his father and his mother , and\n",
      "lesh . And they were both naked , the man and his wife , and were not ashamed .\n",
      "that thou shouldest not eat ? And the man said , The woman whom thou gavest to \n",
      " And the LORD God said , Behold , the man is become as one of us , to know good\n",
      "ce he was taken . So he drove out the man ; and he placed at the east of the ga\n",
      "are Cain , and said , I have gotten a man from the LORD . And she again bare hi\n",
      "arken unto my spee for I have slain a man to my wounding , and a young man to m\n",
      "in a man to my wounding , and a young man to my hurt . If Cain shall be avenged\n",
      "of Adam . In the day that God created man , in the likeness of God made he him \n",
      "y spirit shall not always strive with man , for that he also is fle yet his day\n",
      " . And God saw that the wickedness of man was great in the earth , and that eve\n",
      "it repented the LORD that he had made man on the earth , and it grieved him at \n",
      " . And the LORD said , I will destroy man whom I have created from the face of \n"
     ]
    }
   ],
   "source": [
    "text3.concordance(\"man\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional HW: write your own concorcance()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "text4.dispersion_plot([\"citizens\", \"democracy\", \"freedom\", \"duties\", \"America\", \"women\", \"woman\", \"child\", \"family\", \"families\", \"war\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Displaying 3 of 3 matches:\n",
      "ideal republic , where every man and woman is called under the flag for assignm\n",
      "e have proclaimed that every man and woman on this earth has rights , and digni\n",
      "riend of each nation and every man , woman , and child who seeks a future of pe\n"
     ]
    }
   ],
   "source": [
    "text4.concordance(\"woman\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_number_of_words = len(text4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_unique_words = len(set(text4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06692970116993173"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lexical diversity\n",
    "number_of_unique_words/total_number_of_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14.941049825712529"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_number_of_words/number_of_unique_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "old_, mortal_, a_' old_of old_'\n"
     ]
    }
   ],
   "source": [
    "# Virginia Balseiro​when you get to context, \n",
    "# run a common_context for [\"man\", \"woman\"] in \n",
    "# melville and austen and compare. blew my mind.\n",
    "\n",
    "text1.common_contexts([\"woman\", \"man\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_in a_who young_who a_of a_as a_to young_of of_, a_whose young_.\n",
      "respectable_, charming_, young_, a_, other_in a_whom\n"
     ]
    }
   ],
   "source": [
    "text2.common_contexts([\"woman\", \"man\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<FreqDist with 6833 samples and 141576 outcomes>\n"
     ]
    }
   ],
   "source": [
    "fdist2 = FreqDist(text2)\n",
    "print(fdist2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(',', 9397),\n",
       " ('to', 4063),\n",
       " ('.', 3975),\n",
       " ('the', 3861),\n",
       " ('of', 3565),\n",
       " ('and', 3350),\n",
       " ('her', 2436),\n",
       " ('a', 2043),\n",
       " ('I', 2004),\n",
       " ('in', 1904),\n",
       " ('was', 1846),\n",
       " ('it', 1568),\n",
       " ('\"', 1506),\n",
       " (';', 1419),\n",
       " ('she', 1333),\n",
       " ('be', 1305),\n",
       " ('that', 1297),\n",
       " ('for', 1234),\n",
       " ('not', 1212),\n",
       " ('as', 1179),\n",
       " ('you', 1037),\n",
       " ('with', 971),\n",
       " ('had', 969),\n",
       " ('his', 941),\n",
       " ('he', 895),\n",
       " (\"'\", 883),\n",
       " ('have', 807),\n",
       " ('at', 806),\n",
       " ('by', 737),\n",
       " ('is', 728),\n",
       " ('.\"', 721),\n",
       " ('s', 700),\n",
       " ('Elinor', 684),\n",
       " ('on', 676),\n",
       " ('all', 642),\n",
       " ('him', 633),\n",
       " ('so', 617),\n",
       " ('but', 597),\n",
       " ('which', 592),\n",
       " ('could', 568),\n",
       " ('Marianne', 566),\n",
       " ('my', 551),\n",
       " ('Mrs', 530),\n",
       " ('from', 527),\n",
       " ('would', 507),\n",
       " ('very', 492),\n",
       " ('no', 488),\n",
       " ('their', 463),\n",
       " ('them', 462),\n",
       " ('--', 461),\n",
       " ('been', 440),\n",
       " ('were', 437),\n",
       " ('me', 433),\n",
       " ('they', 428),\n",
       " ('more', 406),\n",
       " ('said', 397),\n",
       " (',\"', 396),\n",
       " ('any', 389),\n",
       " ('what', 375),\n",
       " ('this', 372),\n",
       " ('-', 366),\n",
       " ('every', 361),\n",
       " ('than', 360),\n",
       " ('will', 354),\n",
       " ('or', 353),\n",
       " ('your', 347),\n",
       " ('an', 346),\n",
       " ('such', 340),\n",
       " ('one', 304),\n",
       " ('do', 296),\n",
       " ('But', 289),\n",
       " ('!', 289),\n",
       " ('much', 287),\n",
       " ('sister', 282),\n",
       " ('only', 282),\n",
       " ('must', 279),\n",
       " ('own', 271),\n",
       " ('am', 270),\n",
       " ('Edward', 262),\n",
       " ('when', 261),\n",
       " ('who', 260),\n",
       " ('mother', 258),\n",
       " ('She', 258),\n",
       " ('herself', 255),\n",
       " ('Dashwood', 252),\n",
       " ('if', 249),\n",
       " ('The', 243),\n",
       " ('time', 237),\n",
       " ('know', 230),\n",
       " ('Jennings', 230),\n",
       " ('should', 228),\n",
       " ('are', 224),\n",
       " ('might', 215),\n",
       " ('Willoughby', 215),\n",
       " ('?\"', 213),\n",
       " ('did', 211),\n",
       " ('now', 210),\n",
       " ('there', 209),\n",
       " ('think', 209),\n",
       " ('Miss', 208)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fdist2.most_common(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# practice with table 4.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For Certification we require you to submit a file with solutions \n",
    "to Exercises #5 and #6 \n",
    "\n",
    "☼ Compare the lexical diversity scores for humor and romance fiction in 1.1. Which genre is more lexically diverse?\n",
    "\n",
    "☼ Produce a dispersion plot of the four main protagonists in Sense and Sensibility: Elinor, Marianne, Edward, and Willoughby. What can you observe about the different roles played by the males and females in this novel? Can you identify the couples?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the Q&A\n",
    "\n",
    "Client-Server Architecture, also demonstrates Front End vs Back End engineers' jobs\n",
    "- https://www.scnsoft.com/blog-pictures/web-apps/web_application_architecture-03.png\n",
    "\n",
    "Linting your code: having automatic code cleanup\n",
    "- https://www.pylint.org/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
