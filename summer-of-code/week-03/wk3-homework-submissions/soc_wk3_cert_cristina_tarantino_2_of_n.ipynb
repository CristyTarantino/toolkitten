{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Million Women To Tech:  Summer of Code\n",
    "\n",
    "## Week 3 - Intro to NLP \n",
    "\n",
    "### Day 2 Homeworks - Cristina Tarantino\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# type up the whole Chapter 2 \n",
    "# (the whole of http://www.nltk.org/book/ch02.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading collection 'book'\n",
      "[nltk_data]    | \n",
      "[nltk_data]    | Downloading package abc to ./nltk_data...\n",
      "[nltk_data]    |   Package abc is already up-to-date!\n",
      "[nltk_data]    | Downloading package brown to ./nltk_data...\n",
      "[nltk_data]    |   Package brown is already up-to-date!\n",
      "[nltk_data]    | Downloading package chat80 to ./nltk_data...\n",
      "[nltk_data]    |   Package chat80 is already up-to-date!\n",
      "[nltk_data]    | Downloading package cmudict to ./nltk_data...\n",
      "[nltk_data]    |   Package cmudict is already up-to-date!\n",
      "[nltk_data]    | Downloading package conll2000 to ./nltk_data...\n",
      "[nltk_data]    |   Package conll2000 is already up-to-date!\n",
      "[nltk_data]    | Downloading package conll2002 to ./nltk_data...\n",
      "[nltk_data]    |   Package conll2002 is already up-to-date!\n",
      "[nltk_data]    | Downloading package dependency_treebank to\n",
      "[nltk_data]    |     ./nltk_data...\n",
      "[nltk_data]    |   Package dependency_treebank is already up-to-date!\n",
      "[nltk_data]    | Downloading package genesis to ./nltk_data...\n",
      "[nltk_data]    |   Package genesis is already up-to-date!\n",
      "[nltk_data]    | Downloading package gutenberg to ./nltk_data...\n",
      "[nltk_data]    |   Package gutenberg is already up-to-date!\n",
      "[nltk_data]    | Downloading package ieer to ./nltk_data...\n",
      "[nltk_data]    |   Package ieer is already up-to-date!\n",
      "[nltk_data]    | Downloading package inaugural to ./nltk_data...\n",
      "[nltk_data]    |   Package inaugural is already up-to-date!\n",
      "[nltk_data]    | Downloading package movie_reviews to ./nltk_data...\n",
      "[nltk_data]    |   Package movie_reviews is already up-to-date!\n",
      "[nltk_data]    | Downloading package nps_chat to ./nltk_data...\n",
      "[nltk_data]    |   Package nps_chat is already up-to-date!\n",
      "[nltk_data]    | Downloading package names to ./nltk_data...\n",
      "[nltk_data]    |   Package names is already up-to-date!\n",
      "[nltk_data]    | Downloading package ppattach to ./nltk_data...\n",
      "[nltk_data]    |   Package ppattach is already up-to-date!\n",
      "[nltk_data]    | Downloading package reuters to ./nltk_data...\n",
      "[nltk_data]    |   Package reuters is already up-to-date!\n",
      "[nltk_data]    | Downloading package senseval to ./nltk_data...\n",
      "[nltk_data]    |   Package senseval is already up-to-date!\n",
      "[nltk_data]    | Downloading package state_union to ./nltk_data...\n",
      "[nltk_data]    |   Package state_union is already up-to-date!\n",
      "[nltk_data]    | Downloading package stopwords to ./nltk_data...\n",
      "[nltk_data]    |   Package stopwords is already up-to-date!\n",
      "[nltk_data]    | Downloading package swadesh to ./nltk_data...\n",
      "[nltk_data]    |   Package swadesh is already up-to-date!\n",
      "[nltk_data]    | Downloading package timit to ./nltk_data...\n",
      "[nltk_data]    |   Package timit is already up-to-date!\n",
      "[nltk_data]    | Downloading package treebank to ./nltk_data...\n",
      "[nltk_data]    |   Package treebank is already up-to-date!\n",
      "[nltk_data]    | Downloading package toolbox to ./nltk_data...\n",
      "[nltk_data]    |   Package toolbox is already up-to-date!\n",
      "[nltk_data]    | Downloading package udhr to ./nltk_data...\n",
      "[nltk_data]    |   Package udhr is already up-to-date!\n",
      "[nltk_data]    | Downloading package udhr2 to ./nltk_data...\n",
      "[nltk_data]    |   Package udhr2 is already up-to-date!\n",
      "[nltk_data]    | Downloading package unicode_samples to ./nltk_data...\n",
      "[nltk_data]    |   Package unicode_samples is already up-to-date!\n",
      "[nltk_data]    | Downloading package webtext to ./nltk_data...\n",
      "[nltk_data]    |   Package webtext is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet to ./nltk_data...\n",
      "[nltk_data]    |   Package wordnet is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet_ic to ./nltk_data...\n",
      "[nltk_data]    |   Package wordnet_ic is already up-to-date!\n",
      "[nltk_data]    | Downloading package words to ./nltk_data...\n",
      "[nltk_data]    |   Package words is already up-to-date!\n",
      "[nltk_data]    | Downloading package maxent_treebank_pos_tagger to\n",
      "[nltk_data]    |     ./nltk_data...\n",
      "[nltk_data]    |   Package maxent_treebank_pos_tagger is already up-\n",
      "[nltk_data]    |       to-date!\n",
      "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
      "[nltk_data]    |     ./nltk_data...\n",
      "[nltk_data]    |   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data]    | Downloading package universal_tagset to\n",
      "[nltk_data]    |     ./nltk_data...\n",
      "[nltk_data]    |   Package universal_tagset is already up-to-date!\n",
      "[nltk_data]    | Downloading package punkt to ./nltk_data...\n",
      "[nltk_data]    |   Package punkt is already up-to-date!\n",
      "[nltk_data]    | Downloading package book_grammars to ./nltk_data...\n",
      "[nltk_data]    |   Package book_grammars is already up-to-date!\n",
      "[nltk_data]    | Downloading package city_database to ./nltk_data...\n",
      "[nltk_data]    |   Package city_database is already up-to-date!\n",
      "[nltk_data]    | Downloading package tagsets to ./nltk_data...\n",
      "[nltk_data]    |   Package tagsets is already up-to-date!\n",
      "[nltk_data]    | Downloading package panlex_swadesh to ./nltk_data...\n",
      "[nltk_data]    |   Package panlex_swadesh is already up-to-date!\n",
      "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]    |     ./nltk_data...\n",
      "[nltk_data]    |   Package averaged_perceptron_tagger is already up-\n",
      "[nltk_data]    |       to-date!\n",
      "[nltk_data]    | \n",
      "[nltk_data]  Done downloading collection book\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download(\"book\", download_dir='./nltk_data')\n",
    "nltk.data.path.append('./nltk_data')\n",
    "from nltk.corpus import gutenberg\n",
    "from nltk.corpus import webtext\n",
    "from nltk.corpus import nps_chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['austen-emma.txt',\n",
       " 'austen-persuasion.txt',\n",
       " 'austen-sense.txt',\n",
       " 'bible-kjv.txt',\n",
       " 'blake-poems.txt',\n",
       " 'bryant-stories.txt',\n",
       " 'burgess-busterbrown.txt',\n",
       " 'carroll-alice.txt',\n",
       " 'chesterton-ball.txt',\n",
       " 'chesterton-brown.txt',\n",
       " 'chesterton-thursday.txt',\n",
       " 'edgeworth-parents.txt',\n",
       " 'melville-moby_dick.txt',\n",
       " 'milton-paradise.txt',\n",
       " 'shakespeare-caesar.txt',\n",
       " 'shakespeare-hamlet.txt',\n",
       " 'shakespeare-macbeth.txt',\n",
       " 'whitman-leaves.txt']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get gutenberg file identifiers\n",
    "gutenberg.fileids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "192427"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get words of this text \n",
    "emma = nltk.Text(gutenberg.words('austen-emma.txt'))\n",
    "\n",
    "# and check the amount of words it contains\n",
    "len(emma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Displaying 25 of 25 matches:\n",
      "her father , was sometimes taken by surprize at his being still able to pity ` p\n",
      "them do the other any good .\" \" You surprize me ! Emma must do Harriet good : an\n",
      " Knightley actually looked red with surprize and displeasure , as he stood up , \n",
      "Mr . Elton , and found to his great surprize , that Mr . Elton was actually on h\n",
      "nd aid .\" Emma saw Mrs . Weston ' s surprize , and felt that it must be great , \n",
      " father was quite taken up with the surprize of so sudden a journey , and his fe\n",
      "cy , in all the favouring warmth of surprize and conjecture . She was , moreover\n",
      "she appeared , to have her share of surprize , introduction , and pleasure . The\n",
      "eir plans ; and it was an agreeable surprize to her , therefore , to perceive th\n",
      " talking aunt had taken me quite by surprize , it must have been the death of me\n",
      "of all the dialogue which ensued of surprize , and inquiry , and congratulations\n",
      "e the present . They might chuse to surprize her .\" Mrs . Cole had many to agree\n",
      " the mode of it , the mystery , the surprize , is more like a young woman ' s sc\n",
      "t to her song took her agreeably by surprize -- a second , slightly but correctl\n",
      ".\" \" Oh ! no -- there is nothing to surprize one at all .-- A pretty fortune ; a\n",
      "nt to be considered . Emma ' s only surprize was that Jane Fairfax should accept\n",
      " of your admiration may take you by surprize some day or other .\" Mr . Knightley\n",
      "ration for her will ever take me by surprize .-- I never had a thought of her in\n",
      "h expected by the best judges , for surprize -- but there was great joy . Mr . W\n",
      "e sound of at first , without great surprize . \" So unreasonably early !\" she wa\n",
      "ed Frank Churchill , with a look of surprize and displeasure .-- \" That is easy \n",
      " ; and Emma could imagine with what surprize and mortification she must be retur\n",
      "ttled that Jane should go . Quite a surprize to me ! I had not the least idea !-\n",
      "d . It is impossible to express our surprize . He came to speak to his father on\n",
      "ng engaged !\" Emma even jumped with surprize ;-- and , horror - struck , exclaim\n"
     ]
    }
   ],
   "source": [
    "# occurrence of a given word, together with some context\n",
    "emma.concordance(\"surprize\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 25 26 austen-emma.txt\n",
      "5 26 17 austen-persuasion.txt\n",
      "5 28 22 austen-sense.txt\n",
      "4 34 79 bible-kjv.txt\n",
      "5 19 5 blake-poems.txt\n",
      "4 19 14 bryant-stories.txt\n",
      "4 18 12 burgess-busterbrown.txt\n",
      "4 20 13 carroll-alice.txt\n",
      "5 20 12 chesterton-ball.txt\n",
      "5 23 11 chesterton-brown.txt\n",
      "5 18 11 chesterton-thursday.txt\n",
      "4 21 25 edgeworth-parents.txt\n",
      "5 26 15 melville-moby_dick.txt\n",
      "5 52 11 milton-paradise.txt\n",
      "4 12 9 shakespeare-caesar.txt\n",
      "4 12 8 shakespeare-hamlet.txt\n",
      "4 12 7 shakespeare-macbeth.txt\n",
      "5 36 12 whitman-leaves.txt\n"
     ]
    }
   ],
   "source": [
    "# for each file id display avarage word length, avarage sentence length\n",
    "# and lexical diversity\n",
    "for fileid in gutenberg.fileids():\n",
    "    # raw text of the book not split up into tokens    \n",
    "    num_chars = len(gutenberg.raw(fileid))\n",
    "    num_words = len(gutenberg.words(fileid))\n",
    "    num_sents = len(gutenberg.sents(fileid))\n",
    "    num_vocab = len(set(w.lower() for w in gutenberg.words(fileid)))\n",
    "    print(round(num_chars/num_words), round(num_words/num_sents), round(num_words/num_vocab), fileid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['[', 'The', 'Tragedie', 'of', 'Macbeth', 'by', 'William', 'Shakespeare', '1603', ']'], ['Actus', 'Primus', '.'], ...]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "macbeth_sentence = gutenberg.sents('shakespeare-macbeth.txt')\n",
    "macbeth_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Double',\n",
       " ',',\n",
       " 'double',\n",
       " ',',\n",
       " 'toile',\n",
       " 'and',\n",
       " 'trouble',\n",
       " ';',\n",
       " 'Fire',\n",
       " 'burne',\n",
       " ',',\n",
       " 'and',\n",
       " 'Cauldron',\n",
       " 'bubble']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "macbeth_sentence[1116]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Doubtfull',\n",
       "  'it',\n",
       "  'stood',\n",
       "  ',',\n",
       "  'As',\n",
       "  'two',\n",
       "  'spent',\n",
       "  'Swimmers',\n",
       "  ',',\n",
       "  'that',\n",
       "  'doe',\n",
       "  'cling',\n",
       "  'together',\n",
       "  ',',\n",
       "  'And',\n",
       "  'choake',\n",
       "  'their',\n",
       "  'Art',\n",
       "  ':',\n",
       "  'The',\n",
       "  'mercilesse',\n",
       "  'Macdonwald',\n",
       "  '(',\n",
       "  'Worthie',\n",
       "  'to',\n",
       "  'be',\n",
       "  'a',\n",
       "  'Rebell',\n",
       "  ',',\n",
       "  'for',\n",
       "  'to',\n",
       "  'that',\n",
       "  'The',\n",
       "  'multiplying',\n",
       "  'Villanies',\n",
       "  'of',\n",
       "  'Nature',\n",
       "  'Doe',\n",
       "  'swarme',\n",
       "  'vpon',\n",
       "  'him',\n",
       "  ')',\n",
       "  'from',\n",
       "  'the',\n",
       "  'Westerne',\n",
       "  'Isles',\n",
       "  'Of',\n",
       "  'Kernes',\n",
       "  'and',\n",
       "  'Gallowgrosses',\n",
       "  'is',\n",
       "  'supply',\n",
       "  \"'\",\n",
       "  'd',\n",
       "  ',',\n",
       "  'And',\n",
       "  'Fortune',\n",
       "  'on',\n",
       "  'his',\n",
       "  'damned',\n",
       "  'Quarry',\n",
       "  'smiling',\n",
       "  ',',\n",
       "  'Shew',\n",
       "  \"'\",\n",
       "  'd',\n",
       "  'like',\n",
       "  'a',\n",
       "  'Rebells',\n",
       "  'Whore',\n",
       "  ':',\n",
       "  'but',\n",
       "  'all',\n",
       "  \"'\",\n",
       "  's',\n",
       "  'too',\n",
       "  'weake',\n",
       "  ':',\n",
       "  'For',\n",
       "  'braue',\n",
       "  'Macbeth',\n",
       "  '(',\n",
       "  'well',\n",
       "  'hee',\n",
       "  'deserues',\n",
       "  'that',\n",
       "  'Name',\n",
       "  ')',\n",
       "  'Disdayning',\n",
       "  'Fortune',\n",
       "  ',',\n",
       "  'with',\n",
       "  'his',\n",
       "  'brandisht',\n",
       "  'Steele',\n",
       "  ',',\n",
       "  'Which',\n",
       "  'smoak',\n",
       "  \"'\",\n",
       "  'd',\n",
       "  'with',\n",
       "  'bloody',\n",
       "  'execution',\n",
       "  '(',\n",
       "  'Like',\n",
       "  'Valours',\n",
       "  'Minion',\n",
       "  ')',\n",
       "  'caru',\n",
       "  \"'\",\n",
       "  'd',\n",
       "  'out',\n",
       "  'his',\n",
       "  'passage',\n",
       "  ',',\n",
       "  'Till',\n",
       "  'hee',\n",
       "  'fac',\n",
       "  \"'\",\n",
       "  'd',\n",
       "  'the',\n",
       "  'Slaue',\n",
       "  ':',\n",
       "  'Which',\n",
       "  'neu',\n",
       "  \"'\",\n",
       "  'r',\n",
       "  'shooke',\n",
       "  'hands',\n",
       "  ',',\n",
       "  'nor',\n",
       "  'bad',\n",
       "  'farwell',\n",
       "  'to',\n",
       "  'him',\n",
       "  ',',\n",
       "  'Till',\n",
       "  'he',\n",
       "  'vnseam',\n",
       "  \"'\",\n",
       "  'd',\n",
       "  'him',\n",
       "  'from',\n",
       "  'the',\n",
       "  'Naue',\n",
       "  'toth',\n",
       "  \"'\",\n",
       "  'Chops',\n",
       "  ',',\n",
       "  'And',\n",
       "  'fix',\n",
       "  \"'\",\n",
       "  'd',\n",
       "  'his',\n",
       "  'Head',\n",
       "  'vpon',\n",
       "  'our',\n",
       "  'Battlements']]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "longest_len = max(len(s) for s in macbeth_sentence)\n",
    "[s for s in macbeth_sentence if len(s) == longest_len]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "firefox.txt Cookie Manager: \"Don't allow sites that set removed cookies to se ...\n",
      "grail.txt SCENE 1: [wind] [clop clop clop] \n",
      "KING ARTHUR: Whoa there!  [clop ...\n",
      "overheard.txt White guy: So, do you have any plans for this evening?\n",
      "Asian girl ...\n",
      "pirates.txt PIRATES OF THE CARRIBEAN: DEAD MAN'S CHEST, by Ted Elliott & Terr ...\n",
      "singles.txt 25 SEXY MALE, seeks attrac older single lady, for discreet encoun ...\n",
      "wine.txt Lovely delicate, fragrant Rhone wine. Polished leather and strawb ...\n"
     ]
    }
   ],
   "source": [
    "for fileid in webtext.fileids():\n",
    "    print(fileid, webtext.raw(fileid)[:65], '...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chatroom = nps_chat.posts('10-19-20s_70')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
